<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
<head>
<meta content="text/html; charset=ISO-8859-1" http-equiv="Content-Type">
<title>TRECVID MED11 Scoring Primer</title>
<style type="text/css">
  body { counter-reset: chapter; }
  h2:before { content: counter(chapter) ". "; counter-increment: chapter;  /* Add 1 to chapter */ }
  h2 { counter-reset: section subsection; /* Set section to 0 */ }
  h3:before { content: counter(chapter) "." counter(section) " "; counter-increment: section; }
  h3 { counter-reset: subsection; }
  h4:before { content: counter(chapter) "." counter(section) "." counter(subsection) " "; counter-increment: subsection; }
  a {text-decoration:none}
  pre { border-style: solid; border-width: 1px; margin-left: 5px; padding: 2px 2px 2px 2px; background-color: #DDDDDD; }
</style>
</head>
<body>


<div style="text-align: center;"><big><big><big>TRECVID MED11 Scoring Primer</big></big></big><br>
</div>
<div style="text-align: center;"><small>Last modified: June 15th, 2011</small><br>
</div>
 <br>


<h2>Description</h2>
This document provides a high-level overview of how to use the Detection EVAluation (DEVA) tools  ributed 
within the NIST Framework for Detection Evaluation (F4DE)
toolkit for the <a href="http://www.nist.gov/itl/iad/mig/med11.cfm">TRECVID
MED11 Evaluation</a>.
The Multimedia Event Detection (MED) evaluation track is part of the
TRECVID Evaluation. The multi-year goal of MED is to assemble core
detection technologies into a system that can quickly and accurately
search a multimedia collection for user-defined events. See the web
site for specific details about the evaluation.  The document assumes
the reader is familiar with the MED11 Evaluation Plan.


<p>There are four sections in this document: <a href="#executable">Scoring
script synopsis</a>, <a href="#format">CSV File format definition</a>, an <a
 href="#cliuse">Example command lines to score a MED11 submission</a>,
and <a href="#subcheck">Using the Submission Checker</a>.

The examples below assume the F4DE package has been
installed and is working properly according to the README.&nbsp; This
includes defining the $F4DE_BASE environment variable and
including $F4DE_BASE/bin in your path
variable.

<p>  The examples below also assume that you have obtained and have access
to the content the MED11 DRYRUN
files (<a
href="ftp://jaguar.ncsl.nist.gov/outgoing/MED11_related/MED11_DRYRUN_Files.tar.bz2">MED11_DRYRUN_Files.tar.bz2</a>)
as well as the MED11 Primer files (<a href="ftp://jaguar.ncsl.nist.gov/outgoing/MED11_related/MED11_Primer_Files.tar.bz2">MED11_Primer_Files.tar.bz2</a>).



<a name="executable">
<h2>Scoring Script Synopsis</h2>
</a>

<b>DEVA_cli</b> is the <i>Detection EVAluation command line
interface</i>.  NIST will use DEVA_cli to measure the performance of MED systems.  
The software uses <a href="http://www.sqlite.org">SQLite</a> to manage
the data tables and then uses SQLite compatible queries to select
data to score. The input to the software is a set of <i>Comma Separated Value</i> (CSV) tables as defined in Section 3. 

<p> The MED evaluation tests a system's ability to detect if an event (as defined by an event kit) occurs within a video of the test collection.  An MED system computes the probability that the event occured for each event kit/test video combination, a decision threshold for the event optimizing the primary metric, and the total processing time for the detection of an event.  For the DEVA tools, each time a system computes an event/test video probability, it is called a <i>trial</i>.  Each trial is identified by a unique <b>TrialID</b>.  TrialIDs are grouped into a statistical sample block referred to as a which are identified by a <i>BlockID</i>.  For MED11, the EventIDs are used as BlockIDs. 

<p>  DEVA_cli accepts a variety of input combinations, however, to perform the MED11 scoring with the standard setup, NIST/LDC will provide a set of data files and MED11 systems will generate a set of files.

<UL>
<LI> <b>Provided Data Files</b>: NIST/LDC will provide the following
  database files for use in scoring (all those files will be available
  for DRYRUN but not for MED11TEST)

<UL>
<LI> <b> TrialIndex file: </b> 
The trial index file contains a list of TrialIDs.  Each line contains three columns:
<ul> <li> <i>TrialID</i>: The ID assigned to the trial  
<li> <i>ClipID</i>:  The clip ID to be used in the trial.  The ID is defined in Clip Metadata file below.
<li> <i>EventID</i>: The ID of the event for which the system builds its event agent.  The ID is defined in the Event Database file below
</UL>

<LI> <b> Reference File: </b> The reference CSV file
defines which TrialIDs are target trials (the video contains an
instance of the event) and which TrialIDs are non-target trials (the
video does not contain an instance of the event).  The file 
contain two columns: 
<ul>
<li> <i>TrialID</i>:  <i>(as defined above)</i>
<li> <i>Targ</i>: a two-valued column that must be either <i>y</i> a target or <i>n</i> otherwise. 
</ul>

<LI> <b> Event Database file: </b> 
The event description metadata file maps the <i>EventID</i> to <i>EventName</i>.
<ul>
  <li><i>EventID</i>:   <i>(as defined above)</i>
  <li><i>EventName</i>: is the textual name of the event
</ul>
</li>

<LI> <b> Judgement Meta Data file: </b> 
the ClipID's Event Metadata file (copied from the source database); Judgments for background clips are intentionally incomplete.   

For each unique ClipID,
<ul>
  <li><i>EventID</i>: is the ID of one of the MED-11 events or NULL indicating no event judgment was made.
  <li><i>INSTANCE_TYPE</i>: positive denotes that this clip is a positive (true) instance of the specified event
  <li><i>SYNOPSIS</i>: brief summary of the clip content  
  <li><i>GENRE</i>: data scout judgment about the clip's genre
  <li><i>TOPIC</i>: general topic category for this clip
  <li><i>SCENE</i>: optional freeform description by data scout of the scene/setting for the clip
  <LI><I>OBJECTS</I>: optional freeform description by the data scout of the objects/people shown in the clip
  <LI><i>ACTIVITIES</i>: optional freeform description by the data scout of the activities shown in the clip
  <li><i>INSTANCE_VARIETY</i>: subjective judgment by data scout about whether this clip is more unusual than other instances of this event      
  <li><i>INSTANCE_COMPLEXITY</i>: subjective judgment by data scout about whether this clip is more difficult/complex than other instances of this event
  <li><i>AUDIO_EVIDENCE</i>: does this clip contain audio evidence supporting the event
  <li><i>TEXT_EVIDENCE</i>: does this clip contain text evidence supporting the event
  <li><i>NON_ENG_SPEECH</i>: does this clip contain non-English speech
  <li><i>NON_ENG_TEXT</i>: does this clip contain non-English text
  <li><i>NARRATIVE_AUDIO</i>: does the clip include someone explaining or describing (some or all of) the event step-by-step as they perform it. Empty when the Event is NULL. May be empty for some non-NULL events.
  <li><i>NARRATIVE_TEXT</i>: does the clip include text explaining or describing (some or all of) the event step-by-step as it is performed. Empty when the Event is NULL. May be empty for some non-NULL events.
  <li><i>INSTANCE_COMMENT</i>: optional comment providing additional
  information about why the clip was labeled as a negative
  instance.
</ul>
  
</li>
<LI> <b> Clip Meta Data file: </b> 
general clip metadata including a unique ClipID, associated <i>MEDIA_FILE</i>, <i>CODEC</i>, <i>MD5SUM</i> and <i>DURATION</i>
where:
<ul>
<li><i>ClipID</i>: unique numerical ID for this video/metadata entry (extracted from the RANDOM_MEDIA_FILE information)
<li><i>MEDIA_FILE</i>: randomized, non-chronological filename for the media file corresponding to this entry.
<li><i>MD5SUM</i>: MD5 checksum for the media file corresponding to this entry
<li><i>DURATION</i>: duration in seconds for the media file corresponding to this entry.
</ul>
</li>


</UL>

<li> <b> System Generated Output Files: </b> Per the evaluation plan, MED11 system will generate two CSV formatted files.  
<ul>
  <li> <i> The detection file: </i> This file contains the confidence score for each TrialID in the test.  The file must contain two columns with column headings:
  <ul>
     <li><i>TrialID</i>:  <i>(as defined above)</i>
     <li><i>Score</i>: a floating point value in the range [0.0:1.0]</li>
  </ul>
  
  <li> <i>The threshold file</i>: This file contains information about the processed event.   
It must contain three columns:
  <ul>
  <li><i>EventID</i>:   <i>(as defined above)</i>
  <li><i>DetectionThreshold</i>:  The detection threshold as defined in Section 2.2.2 of the evaluation plan. The value must be in the range [0.0:1.0]
  <li><i>DetectionTPT</i>: The total processing time of the detection
    phase.  The value is unbounded value: see the EvalPlan for details.</li>
  </ul>
</ul>


</LI>
</UL>


<a name="format">
<h2>CSV File Format Definition</h2>
</a>DEVA_cli uses <i>Comma Separated Values</i> (CSV)
files to
generate SQL tables that will be used by the scoring tool. CSV files
are ASCII text files where each line contains comma separate, double quote enclosed values.   The DEVA tools require the first row of a CSV file to contain the
column's header.  The following is a valid CSV file that contains three columns and two rows of data:
</p>
<dir>
<code>
"ID","FirstName","LastName"<br>
"1","John","Doe"</br>
"2","Mary","Smith"
</code>
</dir>


<br>
<a name="cliuse">
<h2>Example command lines to score a MED11 submission</h2>
</a>

  <p><i>For further information about the DEVA_cli tool (available as
part of the F4DE), please refer to its manual:
<code>DEVA_cli --man</code></i></p>

The following is an example of how to score one system run using the default scoring setup using files formatted for submission to NIST.  

<p>The MED11 Primer files (<a href="ftp://jaguar.ncsl.nist.gov/incoming/MED11_Primer/MED11_Primer_Files.tar.bz2">MED11_Primer_Files.tar.bz2</a>) contain system-generated output files for a random system processing the Dry Run data set.  The files are <code>testTEAM_MED11_DEVT_MEDPart_AutoEAG_p-RandomSys_1.detection.csv</code>
and <code>testTEAM_MED11_DEVT_MEDPart_AutoEAG_p-RandomSys_1.threshold.csv</code>.  The file names follow the prescribed structure of the EXP-ID described in Appendix B of the evaluation plan where:

<UL> <LI> The <i>TEAM</i> named "testTEAM" (must not contain underscores),
  <LI> The processed <i>DATA</i> set is "DRYRUN", 
  <LI> The type of <i>MEDTYPE</i> of system is "MEDPart",
  <LI> The style of Event Agent Generation <i>EAG</i> is automatice EAG "AutoEAG",
  <LI> The <i>SYSID</i> is "p-RandomSys", a site-specified string
  (that does not contain underscores) designating the system used. It
  is to begin with p- for a primary system (i.e., your single best
  system) or with c- for any contrastive systems. Note: there can be only one primary system in a given submission and only one submission per TEAM
  <LI> The <i>VERSION</i> number is "1". 
  </UL>
  
Using the MED11 DRYRUN
files (<a href="ftp://jaguar.ncsl.nist.gov/incoming/MED11_DRYRUN_Files.tar.bz2">MED11_DRYRUN_Files.tar.bz2</a>), the following command will score the run:

</doc>
<pre>
% mkdir testTEAM-Results1
% DEVA_cli\
--profile MED11\
--outdir testTEAM-Results1 \
--refcsv DRYRUN_Ref.csv \
--syscsv testTEAM_MED11_DRYRUN_MEDPart_AutoEAG_p-RandomSys_1.detection.csv:detection \
--syscsv testTEAM_MED11_DRYRUN_MEDPart_AutoEAG_p-RandomSys_1.threshold.csv:threshold \
DRYRUN_TrialIndex.csv:TrialIndex \
DRYRUN_ClipMD.csv:ClipMD \
DRYRUN_JudgementMD.csv:JudgementMD \
DRYRUN_EventDB.csv:EventDB
</pre>
where:<br>
<ul>
  <li>The "testTEAM-Results1" directory (which must exist before
running this command) will contain all the output generated by the script.</li>
  <li>The <code>--profile MED11</code> argument provides preconfigured command line options (e.g., the metric, trial selection, join, ...) for the MED11 evaluation</li>
  <li>The CSV filenames use the <code>:</code> notation (example: <code>DRYRUN_ClipMD.csv:ClipMD</code>) to provide simple table names for use in the SQL statements.  </li>
  
<li> The DEVA_cli accepts metadata CSV files at the end of the command line.  The files can contain any metadata about the test material:  the structure of the content is up to the user.    However, the use of <code>--profile MED11</code> option requires one metadata file to be the <i>DRYRUN_TrialIndex.csv:TrialIndex</i>.  It is used to apply the <i>DetectionThreshold</i> in the threshold file to the <i>Scores</i> in the detection file. 


</ul>

The script will run through the four steps of the DEVA_cli scorer and
place result, database and logs in the "<i>testTEAM_Results1</i>" directory.
There are many files generated by the script.  The most notable are:

<UL> 

<LI> <i><a href="ftp://jaguar.ncsl.nist.gov/outgoing/MED11_related/testTEAM-Results1/scoreDB.scores.txt">testTEAM-Results1/scoreDB.scores.txt</a></i>, a text version of the scoring report which
includes five sections for each EventID.   (There is a .csv version of file as well.)
<ul>
  <li> The "Inputs" section:
  <UL>
    <li> <code>#Targ</code>, the number of target TrialIDs. </li>
    <li> <code>#NTarg</code>, the number of non-target TrialIDs. </li>
    <li> <code>#Sys</code>, the number of TrialIDs with system responses.  For MED11 this should equal #Targ + #NTarg. </li>
  </UL>
  <li> The "Actual Decision NDC Analysis" section shows the performance of the system using the <i>DecisionThreshold</i> supplied for the system </li>
  <UL>
    <li> <code>#CorDet</code>, the number target trials correctly detected, (target clips &gt;= <i>DetectionThreshold</i>)</li>
    <li> <code>#Cor!Det</code>, the number of non-target trials correctly NOT detected, (non-target clips &lt; <i>DetectionThreshold</i>)</li>
    <li> <code>#FA</code>, the number of target trials falsely detected, (target clips &lt; the <i>DetectionThreshold</i>)
    <li> <code>#Miss</code>, the number of target trials mistakenly detected, (non-target clips &gt;= <i>DetectionThreshold</i>) </li>
    <li> <code>PFA</code>, #FA / #NTarg</li>
    <li> <code>PMiss</code>, #MD / #Targ</li>
    <li> <code>NDC</code>, the Normalized Detection Cost</li>
    <li> <code>Dec. Thresh</code>, the <i>DecisionThreshold</i></li>
  </UL>
  <li> The "Minimum NormCost Analysis" section shows an analysis of
  the DET curve to find threshold that achieves the minimum NDC
  point. All of the following use definitions similar to the above.
  <ul>
    <li> <code>PFA</code>
    <li> <code>PMiss</code>
    <li> <code>NDC</code>
    <li> <code>Dec. Thresh</code>, the decision threshold where the minimum NDC occurs 
  </UL>
  <li> "DET Curve" shows the PNG filename of the DET curve that EventID. </li>
  <li> Threshold Curve shows the PNG filename that displays PMiss, PFA, and NDC as a function of Decision score for that EventID. </li>

</ul>

<LI> <i><a href="ftp://jaguar.ncsl.nist.gov/outgoing/MED11_related/testTEAM-Results1/scoreDB.det.png">testTEAM-Results1/scoreDB.det.png</a></i>, a single PNG file containing the DET line traces for all of the scored EventIDs. </LI>   

<LI> <i>testTEAM-Results1/scoreDB.det.*.srl.gz</i>, serialized versions of each EventID's DET curve.  These files can be used as input to  <code> DETUtil</code> to produce selective DET Curve plots.  For example to plot just E002 and E003, use following the command.  The produced png file will be 'focusSet.png'.

<pre>
% DETUtil -T "Events E002 and E003" -o focusSet.png testTEAM-Results1/*E002*srl.gz testTEAM-Results1/*E003*srl.gz
</pre>

</ul>

<br>
<a name="clifilter">
<h3>Performing Selective TrialID Scoring</h3>
</a>

DEVA_cli accepts as an option <code>--FilterCMDfile SQLFile</code>
which filters the TrialIDs included in the scoring run.

For sites only participating in some of the events, the default SQL filter will insure that only the <i>TrialID</i>s
listed in the system CSV will be used. <i>A submission checker will
be released soon to other among things verifies that all TrialIDs  for an event are present
in the system file.</i>

The default filter's definition for the MED11 profile (located in the
<code>DEVAcli_filter-MED11.sql</code> file) is as follow:
<pre>
INSERT OR ABORT INTO ResultsTable ( TrialID, BlockID )
  SELECT system.TrialID,TrialIndex.EventID FROM TrialIndex INNER JOIN system
  WHERE system.TrialID==TrialIndex.TrialID;
</pre>


An <b>SQL filter</b>, such as <code>DEVAcli_filter-MED11_primer.sql</code> found in the primer tar file, restricts the selection of TrialIDs to only those whose ClipIDs duration is less than 30 seconds. The SQL command is:

<pre>
INSERT OR ABORT INTO ResultsTable ( TrialID, BlockID )
  SELECT system.TrialID,TrialIndex.EventID FROM TrialIndex INNER JOIN system,ClipMD
  WHERE system.TrialID==TrialIndex.TrialID AND TrialIndex.ClipID==ClipMD.ClipID AND ClipMD.DURATION<30;
</pre>

To use the filter, execute the following commands: 

<pre>
% mkdir testTEAM-Results2
% DEVA_cli\
--profile MED11\
--outdir testTEAM-Results2 \
--refcsv DRYRUN_Ref.csv \
--syscsv testTEAM_MED11_DRYRUN_MEDPart_AutoEAG_p-RandomSys_1.detection.csv:detection \
--syscsv testTEAM_MED11_DRYRUN_MEDPart_AutoEAG_p-RandomSys_1.threshold.csv:threshold \
DRYRUN_ClipMD.csv:ClipMD \
DRYRUN_JudgementMD.csv:JudgementMD \
DRYRUN_TrialIndex.csv:TrialIndex \
DRYRUN_EventDB.csv:EventDB \
--FilterCMDfile DEVAcli_filter-MED11_primer.sql
</pre>

<a name="subcheck">
<h2>Using the Submission Checker</h2>
</a>

Before providing a TEAM submission (as detailed in the Eval Plan in
Appendix B), it is required that submissions passs the Submission
Checker in order to be accepted.

In this example we will validate the <a
href="ftp://jaguar.ncsl.nist.gov/outgoing/MED11_related/MED11_testTEAM_DRYRUN_2.tar.bz2">MED11_testTEAM_DRYRUN_2.tar.bz2</a>
submission for the <i>testTEAM</i> TEAM and for the <i>DRYRUN</i> DATA
mode.

The content of the archive is as follow:
<pre>
output/
output/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1/
output/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1.detection.csv
output/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1.threshold.csv
output/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1/testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1.txt
</pre>

This submission only contains one EXPID
(testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1).
<br>
For testing purposes, the content of the
<code>testTEAM_MED11_DRYRUN_MEDFull_AutoEAG_p-RandomSys_1.txt</code>
was left empty, but it must be present and contain information
detailled in the EVAL Plan.
<br>
In order to run the Submission Checker, the <b>TrialIndex</b> CSV file
must be available, as it is used to do generate the system database as
well doing some <i>EventID</i> and <i>TrialID</i> checks.

Running the submission checker is then done as follow:

<pre>
% TV11MED-SubmissionChecker --TrialIndex DRYRUN_TrialIndex.csv MED11_testTEAM_DRYRUN_2.tar.bz2
</pre>

In case of success, a 'ok' should appear next to the submission name
(<code>MED11_testTEAM_DRYRUN_2.tar.bz2: ok</code>) and the program
will exit with an OK exit status.
<br>
It is recommended to run the tool with the <code>--Verbose</code>
option in order to see a step-by-step description of the steps performed.

</body>
</html>
